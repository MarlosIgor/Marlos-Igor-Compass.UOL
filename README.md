# Apresenta√ß√£o üé¨

Ol√°! Meu nome √© Marlos Igor Paulino Barros e sou natural da cidade de √Åguas Belas. Atualmente, estou cursando o quarto semestre no Centro Universit√°rio Maur√≠cio de Nassau. Tenho experi√™ncia nas √°reas de tecnologia, com conhecimentos em Java, Spring, Microservi√ßos, SQL e AWS.


# Sprints üë®‚Äçüíª

- [‚úÖ Cultura √Ågil e Seguran√ßa 0Ô∏è‚É£](Cultura_Agil_e_Seguranca):
Conclu√≠ o curso ‚ÄúSeguran√ßa em Aplica√ß√µes Web‚Äù, o qual me proporcionou uma compreens√£o abrangente dos principais conceitos e t√©cnicas de seguran√ßa para o desenvolvimento de aplica√ß√µes web. Al√©m disso, tamb√©m conclui o curso de M√©todos √°geis de A a Z: o curso completo, no qual aprendi Scrum, Lean, Kanban, Design Sprint, Spotify Squad, Smart, eXtreme Programming, Trello, Asana e muito mais! Essas experi√™ncias me proporcionaram um conjunto valioso de habilidades e conhecimentos que pretendo aplicar em futuros projetos profissionais. 

- [‚úÖ Sprint 1Ô∏è‚É£](Sprint_1/): 
Conclu√≠ dois cursos importantes: Git e GitHub, e Linux para Desenvolvedores. Agora estou mais capacitado e preparado para lidar com controle de vers√£o e colabora√ß√£o em projetos, al√©m de ter adquirido habilidades relevantes para a administra√ß√£o de servidores web. Esses cursos contribuem para o meu desenvolvimento profissional.

- [‚úÖ Sprint 2Ô∏è‚É£](Sprint_2/): 
Conclu√≠ o curso de Big Data Fundamentos 3.0 e o curso de SQL para An√°lise de Dados. Esses cursos me proporcionaram uma base s√≥lida em conceitos de Big Data, sistemas de armazenamento, processamento paralelo, Cloud Computing, MLOps, DataOps, Dados Como Servi√ßo e ETL. Tamb√©m aprendi a manipular dados usando SQL, incluindo como criar consultas avan√ßadas, otimizar consultas e utilizar fun√ß√µes agregadas.

- [‚úÖ Sprint 3Ô∏è‚É£](Sprint_3/): 
Conclu√≠ o Curso de Python, abrangendo desde conceitos b√°sicos at√© t√©cnicas avan√ßadas. O curso incluiu temas como Algoritmos, Estruturas de Dados, Fundamentos, Orienta√ß√£o a Objeto e Programa√ß√£o Funcional. 

- [‚úÖ Sprint 4Ô∏è‚É£](Sprint_4/):
Conclu√≠ o curso de "Estat√≠stica Descritiva com Python", onde aprendi a analisar dados utilizando bibliotecas Python como NumPy e Pandas, calculando medidas estat√≠sticas e visualizando informa√ß√µes relevantes. Al√©m disso, finalizei os cursos de "Docker para Desenvolvedores com Docker Swarm e Kubernetes", adquirindo habilidades em cria√ß√£o, implanta√ß√£o e escalonamento de aplicativos por meio de cont√™ineres. Agora estou capacitado a unir an√°lise de dados estat√≠sticos com implementa√ß√µes de aplicativos mais eficientes e escal√°veis usando tecnologias de cont√™ineres.

- [‚úÖ Sprint 5Ô∏è‚É£](Sprint_5/):
Conclu√≠ uma s√©rie de cursos da AWS que abordaram aspectos de neg√≥cios e t√©cnicos da plataforma de computa√ß√£o em nuvem. Os cursos incluem AWS Partner: Sales Accreditation (Business), AWS Cloud Quest: Cloud Practitioner, AWS Partner: Accreditation (Technical), AWS Partner: Cloud Economics Accreditation e AWS Certified Cloud Practitioner.
No geral, esses cursos me proporcionaram uma base s√≥lida e ampla de conhecimento na plataforma AWS, capacitando-me a abordar tanto os aspectos de neg√≥cios quanto os t√©cnicos da computa√ß√£o em nuvem. Isso me permite oferecer solu√ß√µes e servi√ßos da AWS de maneira mais eficaz e atender √†s diversas necessidades dos clientes.

- [‚úÖ Sprint 6Ô∏è‚É£](Sprint_6/):
Conclu√≠ uma s√©rie de cursos da AWS relacionados √† an√°lise de dados e √† computa√ß√£o em nuvem. Os cursos incluem AWS Skill Builder - Data Analytics Fundamentals, AWS Partner: Data Analytics on AWS, AWS Skill Builder - Introduction to Amazon Kinesis Streams, AWS Skill Builder - Introduction to Amazon Kinesis Analytics, AWS Skill Builder - Introduction to Amazon Elastic MapReduce (EMR), AWS Skill Builder - Introduction to Amazon Athena, AWS Skill Builder - Introduction to Amazon Quicksight, AWS Skill Builder - Introduction to AWS IoT Analytics, AWS Skill Builder - Getting Started with Amazon Redshift, AWS Skill Builder - Deep Dive into Concepts and Tools for Analyzing Streaming Data, AWS Skill Builder - Best Practices for Data Warehousing with Amazon Redshift, AWS Skill Builder - Serverless Analytics e AWS Skill Builder - Why Analytics for Games.
Esses cursos proporcionaram uma base s√≥lida de conhecimento em an√°lise de dados e nas solu√ß√µes de computa√ß√£o em nuvem da AWS. Eles me capacitaram a abordar aspectos tanto de neg√≥cios quanto t√©cnicos relacionados √† an√°lise de dados na plataforma AWS. Isso me permite oferecer solu√ß√µes de an√°lise de dados e servi√ßos da AWS de maneira mais eficaz, atendendo √†s diversas necessidades dos clientes no campo da an√°lise de dados e computa√ß√£o em nuvem.

# Desafio Final üß†  

- [‚úÖ Sprint 7Ô∏è‚É£](Sprint_7/):
Conclu√≠ dois cursos essenciais no campo da an√°lise de dados em grande escala e processamento de big data: "Learn By Example: Hadoop, MapReduce for Big Data Problems" e "Forma√ß√£o Spark com PySpark: O Curso Completo". Estes cursos me proporcionaram uma base s√≥lida para lidar com grandes volumes de dados.
No curso de Hadoop e MapReduce, aprendi a utilizar essas ferramentas para processar e analisar dados em larga escala, o que me permite oferecer solu√ß√µes eficazes para clientes que enfrentam desafios relacionados ao processamento de big data.
O curso de Spark com PySpark aprofundou meu conhecimento sobre o Apache Spark e sua integra√ß√£o com Python, capacitando-me para an√°lises em tempo real e processamento eficiente de grandes volumes de dados. Isso me permite atender √†s diversas necessidades dos clientes em busca de insights valiosos e an√°lises avan√ßadas em tempo real.
Em resumo, esses cursos expandiram minhas habilidades e me tornaram mais capaz de oferecer solu√ß√µes eficazes em an√°lise de big data.

- [‚úÖ Sprint 8Ô∏è‚É£](Sprint_8/):
A segunda parte do projeto foi conclu√≠da com sucesso, com a captura de dados do TMDB feita por meio de uma fun√ß√£o AWS Lambda em Python. Os dados foram armazenados no Amazon S3 na camada RAW Zone, mantendo o formato original em JSON. Al√©m disso, os dados foram agrupados em arquivos de 100 registros cada, para organiza√ß√£o eficiente. Para garantir a regularidade da coleta, foi utilizado o Amazon EventBridge para disparar a fun√ß√£o Lambda a cada 5 dias.

- [‚úÖ Sprint 9Ô∏è‚É£](Sprint_9/):
A terceira parte do projeto foi conclu√≠da com sucesso. Os dados foram convertidos de JSON para Parquet, refinados para gerar insights na camada REF e salvos. O crawler foi utilizado para realizar consultas no Athena.  

- [‚úÖ Sprint üîü](Sprint_10/):
A quarta fase do projeto foi conclu√≠da com sucesso. Utilizando as tabelas da camada de insights refinados no Athena, criei views espec√≠ficas para filmes e s√©ries do g√™nero a√ß√£o e aventura. Al√©m disso, elaborei dashboards no AWS QuickSight para apresentar de forma visual e intuitiva informa√ß√µes sobre o TOP10 de filmes e s√©ries mais populares.